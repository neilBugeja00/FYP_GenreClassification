{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "199186fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow import keras\n",
    "from keras_tuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fade6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"csv_fma_10secs_data.csv\"\n",
    "\n",
    "sr=22050\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7abfc25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_28_36\n"
     ]
    }
   ],
   "source": [
    "currentDateAndTime = datetime.datetime.now()\n",
    "\n",
    "LOG_DIR = currentDateAndTime.strftime(\"%H_%M_%S\")\n",
    "\n",
    "print(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083af642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read MFCC data from CSV\n",
    "def csv_read_data(csv_path):\n",
    "    # Load data from CSV file\n",
    "    with open(csv_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "\n",
    "        next(reader)\n",
    "\n",
    "        # Initialize lists to hold genre and MFCC data\n",
    "        genres = []\n",
    "        mfcc = []\n",
    "\n",
    "        # Iterate over each row of the CSV file\n",
    "        for row in reader:\n",
    "            # Extract genre and MFCC data from the row\n",
    "            genre = int(row[0])\n",
    "            mfcc_data = json.loads(row[1])\n",
    "\n",
    "            # Append genre and MFCC data to lists\n",
    "            genres.append(genre)\n",
    "            mfcc.append(mfcc_data)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(mfcc)\n",
    "    y = np.array(genres)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cbdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use stratified split to seperate data into training, validation and test\n",
    "\n",
    "def stratified_split_dataset(inputs, targets, split_size):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=split_size, random_state=42)\n",
    "    \n",
    "    train_val_indices, test_indices = next(sss.split(inputs, targets))\n",
    "    inputs_train_val, targets_train_val = inputs[train_val_indices], targets[train_val_indices]\n",
    "    \n",
    "    sss_train = StratifiedShuffleSplit(n_splits=1, test_size=split_size, random_state=43)\n",
    "    train_indices, val_indices = next(sss_train.split(inputs_train_val, targets_train_val))\n",
    "    \n",
    "    inputs_train, targets_train = inputs_train_val[train_indices], targets_train_val[train_indices]\n",
    "    inputs_val, targets_val = inputs_train_val[val_indices], targets_train_val[val_indices]\n",
    "    inputs_test, targets_test = inputs[test_indices], targets[test_indices]\n",
    "    \n",
    "    #Needed for compatibility reasons\n",
    "    inputs_train = inputs_train[...,np.newaxis]\n",
    "    inputs_val = inputs_val[...,np.newaxis]\n",
    "    inputs_test=  inputs_test[..., np.newaxis]\n",
    "    \n",
    "    \n",
    "    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0bc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = csv_read_data(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac20255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "Xtrain, Xval, Xtest, ytrain, yval, ytest =stratified_split_dataset(inputs, targets, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76d9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (Xtrain.shape[1], Xtrain.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78740829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1785af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_existing_code(units, activation, lr, dropout, layers):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(units, (3,3), activation=activation, input_shape=(417, 40, 1)),)\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    \n",
    "    for i in range (layers):\n",
    "        model.add(tf.keras.layers.Conv2D(units, (3,3), activation=activation, input_shape=(417, 40, 1)),)\n",
    "        model.add(tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        if dropout:\n",
    "            model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "        \n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units, activation='relu')) \n",
    "    model.add(tf.keras.layers.Dense(len(np.unique(targets)), activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd9d874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=32, max_value=128, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    layers = hp.Int(\"n_layers\", min_value=1, max_value=3, step=1)\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = call_existing_code(\n",
    "        units=units, activation=activation, lr=lr, dropout=dropout, layers = layers\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "68423036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fea0c188250>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b6613fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5000,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"./trials/tb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d485f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "n_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf615107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 18s]\n",
      "val_accuracy: 0.6228280365467072\n",
      "\n",
      "Best val_accuracy So Far: 0.6384062469005585\n",
      "Total elapsed time: 00h 05m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    Xtrain,\n",
    "    ytrain,\n",
    "    validation_data=(Xval, yval),\n",
    "    epochs=50,\n",
    "    callbacks=[keras.callbacks.TensorBoard(\"./trials/tb_logs\"),tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)] \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1b1600c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units: 96\n",
      "activation: relu\n",
      "dropout: False\n",
      "n_layers: 2\n",
      "lr: 0.0018308334177090633\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print out the values of the best hyperparameters\n",
    "for hp in best_hps.values:\n",
    "    print(f\"{hp}: {best_hps.get(hp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34a60650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 415, 38, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 208, 19, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 208, 19, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 206, 17, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 103, 9, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 103, 9, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 101, 7, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 51, 4, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 51, 4, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 49, 2, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 25, 1, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 25, 1, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,406\n",
      "Trainable params: 54,150\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(417, 40, 1))\n",
    "best_model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
